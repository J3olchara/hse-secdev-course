# Отчет по заданиям P07 и P08

## задание P07 - контейнеризация и базовый харднинг

В этом задании нужно было запихнуть приложение wishlist api в контейнер и настроить базовую безопасность. по сути требовалось сделать dockerfile с multi-stage build, docker-compose для локального запуска, и прикрутить инструменты для сканирования уязвимостей.

### что сделал

Создал:
- dockerfile с multi-stage build
- docker-compose.yaml для запуска всего стека
- .dockerignore чтобы не тащить мусор в образ
- ci пайплайн для проверки безопасности

#### про dockerfile

Выбрал python:3.11-slim как базовый образ. Долго думал между alpine и slim, в итоге остановился на slim потому что с ним меньше проблем с компиляцией python пакетов. alpine конечно легче, но там постоянно что-то не собирается из-за musl вместо glibc.

dockerfile разделил на две стадии. В первой (builder) ставлю poetry и все зависимости. Тут важный момент - я прописал точные версии системных пакетов типа curl, gcc, libpq-dev. Это чтобы сборка была воспроизводимой и через месяц не внезапно сломалась из-за обновления какого-нибудь пакета.

Во второй стадии (runtime) копирую только виртуальное окружение, без всяких build-инструментов. gcc и компания там не нужны, это только место жрет. Образ в итоге получается намного меньше.

По безопасности сделал такие вещи:
- завел отдельного пользователя appuser (uid 1000) и запускаю от него, чтобы не от root
- настроил права на файлы - /app читается, а /app/app защищен построже
- добавил healthcheck который каждые 30 секунд дергает /health endpoint

честно говоря, сначала забыл про healthcheck и потом полчаса разбирался почему контейнер в compose не становится healthy. оказалось надо было curl установить в runtime образе, а я его только в builder оставил.

#### docker-compose.yaml

тут у меня четыре сервиса:

nginx - принимает запросы снаружи и проксирует в приложение. взял alpine образ потому что он легкий, и для nginx этого достаточно.

app - само приложение wishlist api. запускается только когда БД готова и миграции прошли, иначе падает с ошибками соединения.

postgres - база данных. postgresql 15.7 на alpine. данные складываются в volume чтобы не потерялись когда контейнер пересоздаешь.

migrations - отдельный сервис который один раз запускает alembic миграции и завершается. сначала хотел миграции в самом app при старте делать, но это не очень правильно - если несколько реплик поднимается, они все одновременно будут миграции пытаться накатить.

для всех сервисов прописал:
- no-new-privileges:true - чтобы процессы не могли получить больше прав
- cap_drop: ALL - убрал все capabilities
- для nginx вернул NET_BIND_SERVICE чтобы мог на 80 порту слушать
- у каждого healthcheck свой
- все секреты вынес в .env

#### .dockerignore

добавил туда все что не должно попасть в образ - .git, __pycache__, виртуальные окружения, тесты, .env с секретами, базы данных. это ускоряет сборку и уменьшает размер контекста.

#### ci для контейнеров

настроил отдельный workflow container-security.yml с проверками:

hadolint - линтер для dockerfile. проверяет что все по best practices написано, нет лишних слоев и тд.

build-and-test - собирает образ и проверяет что контейнер не от root запускается и healthcheck работает. сначала тест на healthcheck постоянно падал, оказалось надо было подождать секунд 20 пока приложение стартует.

trivy - сканирует на уязвимости. проверяет и базовый образ и все зависимости. если находит больше 5 критических уязвимостей, билд падает. пару раз приходилось обновлять версии пакетов чтобы избавиться от критичных cve.

compose-check - проверяет что docker-compose.yaml валидный и в нем нет хардкодженных паролей.

### что получилось

образ весит около 200-250 мб, для python приложения это нормально. multi-stage build реально помог - без него было под 500 мб.

все проверки безопасности зеленые:
- hadolint не ругается
- контейнер от non-root пользователя работает
- healthcheck показывает healthy
- trivy находит только минорные уязвимости в базовых пакетах debian

docker compose up поднимает весь стек без проблем. можно локально все потестить.

---

## задание P08 - CI/CD minimal

тут надо было настроить базовый ci/cd пайплайн с автоматическим тестированием, линтингом и деплоем. плюс правильно сделать кэширование, секреты и артефакты.

### что сделал

сделал несколько ci workflows для разных задач.

#### ci.yml - основной пайплайн

этот workflow срабатывает на каждый push и pull request. состоит из двух частей.

первая часть - test job:

настройка окружения - сделал матрицу для python 3.11 и 3.12. сначала думал только 3.11 оставить, но решил что лучше сразу проверять совместимость с новой версией. ставлю poetry для управления зависимостями.

кэширование - настроил кэш для poetry зависимостей. ключ зависит от версии python и хеша poetry.lock. это реально ускоряет ci, потому что зависимости не надо каждый раз качать заново. без кэша job минут 7-8 выполнялся, с кэшем 3-5 минут.

линтинг - прогоняю три проверки:
- ruff для поиска проблем в коде
- black для проверки форматирования
- isort для проверки порядка импортов

честно говоря ruff довольно придирчивый, пришлось местами код переписывать чтобы он не ругался.

тесты - запускаю pytest с coverage. делаю отчеты в трех форматах - xml для интеграций, html чтобы можно было в браузере посмотреть, и junit.xml для ci. все складывается в папку reports.

артефакты - загружаю все отчеты как артефакты github actions. настроил if: always() чтобы артефакты сохранялись даже если тесты упали. для каждой версии python свой набор артефактов получается.

вторая часть - deploy-staging job. это mock деплоя, потому что реального staging окружения нет:

- запускается только если тесты прошли (needs: test)
- работает для main ветки и pull requests
- выводит инфу про деплой - sha коммита, ветку, url окружения
- использует секреты и переменные (DEPLOY_KEY, STAGING_URL)

по безопасности настроил:

permissions: contents: read - минимальные права для workflow. по умолчанию там больше прав дается, а лучше ограничить.

concurrency - чтобы для одной ветки одновременно только один запуск был. если новый коммит пушишь, старый запуск отменяется. очень удобно когда быстро несколько фиксов пушаешь.

timeout-minutes - ограничение по времени. один раз у меня тесты зависли и полтора часа висели, после этого timeout поставил.

секреты через ${{ secrets.* }} передаются и в логи не попадают.

#### container-security.yml

этот workflow я уже в p07 описывал. он для проверки безопасности контейнеров, запускается при изменениях dockerfile или docker-compose.yaml, и можно вручную запустить.

#### ci-sast-secrets.yml

workflow для статического анализа безопасности:

semgrep - сканирует код на уязвимости. использую стандартные правила (p/ci) плюс свои кастомные из security/semgrep/rules.yml. свои правила добавлял потому что стандартные не все паттерны небезопасного кода ловят.

gitleaks - ищет случайно закоммиченные секреты. результаты в EVIDENCE/P10/ сохраняются. один раз нашел что в старых коммитах был test api key, хорошо что это был тестовый а не настоящий.

оба инструмента в docker контейнерах запускаются, так проще и воспроизводимее.

### что получилось

ci работает довольно быстро - 3-5 минут на сборку и тесты благодаря кэшированию. матрица гарантирует что код на обеих версиях python нормально работает. все артефакты автоматически сохраняются.

по безопасности:
- секреты через github secrets изолированы
- минимальные permissions у workflows
- нет хардкодженных паролей в коде
- concurrency не дает запускам дублироваться

cd часть:
- настроен mock-деплой в staging
- после успешных тестов имитируется деплой
- можно легко заменить на реальный деплой, просто команды kubectl или docker push добавить

все проверки зеленые.

---

## общие выводы

эти два задания хорошо друг друга дополняют и в итоге получается полный цикл разработки.

p07 дал воспроизводимое окружение через docker. можно легко запустить локально или в любом облаке. контейнеры защищены базовыми практиками безопасности и регулярно сканируются на уязвимости.

p08 автоматизировал проверку качества кода и безопасности. теперь каждое изменение автоматом тестируется и сканируется, можно деплоить без ручного вмешательства.

вместе получается:
- быстрый локальный запуск для разработки
- автоматическая проверка качества и безопасности
- воспроизводимые сборки
- защита от случайных ошибок и уязвимостей
- готовность к продакшн деплою

было не без проблем - пару раз ci падал из-за timeout, триvy находил критические уязвимости в зависимостях которые пришлось патчить, healthcheck не работал пока curl не добавил. но в целом все заработало.

что можно еще улучшить:
- добавить интеграционные тесты в отдельных контейнерах
- настроить реальный деплой в kubernetes или какое-нибудь облако
- прикрутить мониторинг и алертинг
- расширить security scanning дополнительными инструментами
- настроить автоматический rollback если что-то сломается

